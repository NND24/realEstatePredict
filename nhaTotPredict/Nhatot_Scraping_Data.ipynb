{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # Disable GPU acceleration\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Bypass OS security model\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Overcome limited resource problems\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36\")  # Add a user-agent string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crawl links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl links mua bán nhà ở from nhatot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed: Message: disconnected: not connected to DevTools\n",
      "  (failed to check if window was closed: disconnected: not connected to DevTools)\n",
      "  (Session info: chrome=128.0.6613.120)\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00DF8213+26163]\n",
      "\t(No symbol) [0x00D89CC4]\n",
      "\t(No symbol) [0x00C824C3]\n",
      "\t(No symbol) [0x00C6D118]\n",
      "\t(No symbol) [0x00C6D039]\n",
      "\t(No symbol) [0x00C84960]\n",
      "\t(No symbol) [0x00D03FB9]\n",
      "\t(No symbol) [0x00CEAA56]\n",
      "\t(No symbol) [0x00CBBE89]\n",
      "\t(No symbol) [0x00CBC8CD]\n",
      "\tGetHandleVerifier [0x010CD313+2996019]\n",
      "\tGetHandleVerifier [0x01121B89+3342249]\n",
      "\tGetHandleVerifier [0x00E87AEF+614159]\n",
      "\tGetHandleVerifier [0x00E8F17C+644508]\n",
      "\t(No symbol) [0x00D927FD]\n",
      "\t(No symbol) [0x00D8F6F8]\n",
      "\t(No symbol) [0x00D8F895]\n",
      "\t(No symbol) [0x00D81C16]\n",
      "\tBaseThreadInitThunk [0x76D9FCC9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x772D80CE+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x772D809E+238]\n",
      "\n",
      "Attempt 1 failed: Could not reach host. Are you offline?\n",
      "Attempt 2 failed: Could not reach host. Are you offline?\n",
      "Attempt 3 failed: Could not reach host. Are you offline?\n",
      "Max retries reached. Skipping this page.\n",
      "Attempt 1 failed: Could not reach host. Are you offline?\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize the array to store the links\n",
    "arr = []\n",
    "start_page = 1\n",
    "end_page = 1000\n",
    "\n",
    "# Retry logic\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "for page in range(start_page, end_page + 1):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Initialize WebDriver for each page\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "            url = f\"https://www.nhatot.com/mua-ban-nha-dat?page={page}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # Use explicit wait for better control\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, 'AdItem_adItem__gDDQT')))\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Find all the links with the specified class\n",
    "            a_tags = soup.find_all(\"a\", class_='AdItem_adItem__gDDQT')\n",
    "\n",
    "            # Append the full link to the array\n",
    "            for a in a_tags:\n",
    "                full_link = \"https://www.nhatot.com\" + a['href']\n",
    "                arr.append(full_link)\n",
    "\n",
    "            driver.quit()\n",
    "            break  # Break if the request was successful\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            driver.quit()\n",
    "            if attempt + 1 == MAX_RETRIES:\n",
    "                print(\"Max retries reached. Skipping this page.\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(arr, columns=[\"Links\"])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('muaBanNhaOLinks.csv', index=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl links mua bán căn hộ chung cư from nhatot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array to store the links\n",
    "arr = []\n",
    "start_page = 1\n",
    "end_page = 100\n",
    "\n",
    "# Retry logic\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "for page in range(start_page, end_page + 1):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Initialize WebDriver for each page\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "            url = f\"https://www.nhatot.com/mua-ban-can-ho-chung-cu?page={page}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # Use explicit wait for better control\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, 'AdItem_adItem__gDDQT')))\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Find all the links with the specified class\n",
    "            a_tags = soup.find_all(\"a\", class_='AdItem_adItem__gDDQT')\n",
    "\n",
    "            # Append the full link to the array\n",
    "            for a in a_tags:\n",
    "                full_link = \"https://www.nhatot.com\" + a['href']\n",
    "                arr.append(full_link)\n",
    "\n",
    "            driver.quit()\n",
    "            break  # Break if the request was successful\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            driver.quit()\n",
    "            if attempt + 1 == MAX_RETRIES:\n",
    "                print(\"Max retries reached. Skipping this page.\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(arr, columns=[\"Links\"])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('muaBanCanHoChungCuLinks.csv', index=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl links mua bán mặt bằng from nhatot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array to store the links\n",
    "arr = []\n",
    "start_page = 1\n",
    "end_page = 1000\n",
    "\n",
    "# Retry logic\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "for page in range(start_page, end_page + 1):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Initialize WebDriver for each page\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "            url = f\"https://www.nhatot.com/sang-nhuong-van-phong-mat-bang-kinh-doanh?page={page}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # Use explicit wait for better control\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, 'AdItem_adItem__gDDQT')))\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Find all the links with the specified class\n",
    "            a_tags = soup.find_all(\"a\", class_='AdItem_adItem__gDDQT')\n",
    "\n",
    "            # Append the full link to the array\n",
    "            for a in a_tags:\n",
    "                full_link = \"https://www.nhatot.com\" + a['href']\n",
    "                arr.append(full_link)\n",
    "\n",
    "            driver.quit()\n",
    "            break  # Break if the request was successful\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            driver.quit()\n",
    "            if attempt + 1 == MAX_RETRIES:\n",
    "                print(\"Max retries reached. Skipping this page.\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(arr, columns=[\"Links\"])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('muaBanMatBangLinks.csv', index=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl links mua bán đất from nhatot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array to store the links\n",
    "arr = []\n",
    "start_page = 1\n",
    "end_page = 1000\n",
    "\n",
    "# Retry logic\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "for page in range(start_page, end_page + 1):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Initialize WebDriver for each page\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "            url = f\"https://www.nhatot.com/mua-ban-dat?page={page}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # Use explicit wait for better control\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, 'AdItem_adItem__gDDQT')))\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Find all the links with the specified class\n",
    "            a_tags = soup.find_all(\"a\", class_='AdItem_adItem__gDDQT')\n",
    "\n",
    "            # Append the full link to the array\n",
    "            for a in a_tags:\n",
    "                full_link = \"https://www.nhatot.com\" + a['href']\n",
    "                arr.append(full_link)\n",
    "\n",
    "            driver.quit()\n",
    "            break  # Break if the request was successful\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            driver.quit()\n",
    "            if attempt + 1 == MAX_RETRIES:\n",
    "                print(\"Max retries reached. Skipping this page.\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(arr, columns=[\"Links\"])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('muaBanDatLinks.csv', index=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl links cho thuê căn hộ chung cư from nhatot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array to store the links\n",
    "arr = []\n",
    "start_page = 1\n",
    "end_page = 1000\n",
    "\n",
    "# Retry logic\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "for page in range(start_page, end_page + 1):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Initialize WebDriver for each page\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "            url = f\"https://www.nhatot.com/thue-can-ho-chung-cu?page={page}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # Use explicit wait for better control\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, 'AdItem_adItem__gDDQT')))\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Find all the links with the specified class\n",
    "            a_tags = soup.find_all(\"a\", class_='AdItem_adItem__gDDQT')\n",
    "\n",
    "            # Append the full link to the array\n",
    "            for a in a_tags:\n",
    "                full_link = \"https://www.nhatot.com\" + a['href']\n",
    "                arr.append(full_link)\n",
    "\n",
    "            driver.quit()\n",
    "            break  # Break if the request was successful\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            driver.quit()\n",
    "            if attempt + 1 == MAX_RETRIES:\n",
    "                print(\"Max retries reached. Skipping this page.\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(arr, columns=[\"Links\"])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('choThueCanHoChungCuLinks.csv', index=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl links cho thuê nhà ở from nhatot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array to store the links\n",
    "arr = []\n",
    "start_page = 1\n",
    "end_page = 1000\n",
    "\n",
    "# Retry logic\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "for page in range(start_page, end_page + 1):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Initialize WebDriver for each page\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "            url = f\"https://www.nhatot.com/thue-nha-dat?page={page}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # Use explicit wait for better control\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, 'AdItem_adItem__gDDQT')))\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Find all the links with the specified class\n",
    "            a_tags = soup.find_all(\"a\", class_='AdItem_adItem__gDDQT')\n",
    "\n",
    "            # Append the full link to the array\n",
    "            for a in a_tags:\n",
    "                full_link = \"https://www.nhatot.com\" + a['href']\n",
    "                arr.append(full_link)\n",
    "\n",
    "            driver.quit()\n",
    "            break  # Break if the request was successful\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            driver.quit()\n",
    "            if attempt + 1 == MAX_RETRIES:\n",
    "                print(\"Max retries reached. Skipping this page.\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(arr, columns=[\"Links\"])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('choThueNhaOLinks.csv', index=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl links cho thuê mặt bằng from nhatot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array to store the links\n",
    "arr = []\n",
    "start_page = 1\n",
    "end_page = 1000\n",
    "\n",
    "# Retry logic\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "for page in range(start_page, end_page + 1):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Initialize WebDriver for each page\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "            url = f\"https://www.nhatot.com/thue-van-phong-mat-bang-kinh-doanh?page={page}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # Use explicit wait for better control\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, 'AdItem_adItem__gDDQT')))\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Find all the links with the specified class\n",
    "            a_tags = soup.find_all(\"a\", class_='AdItem_adItem__gDDQT')\n",
    "\n",
    "            # Append the full link to the array\n",
    "            for a in a_tags:\n",
    "                full_link = \"https://www.nhatot.com\" + a['href']\n",
    "                arr.append(full_link)\n",
    "\n",
    "            driver.quit()\n",
    "            break  # Break if the request was successful\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            driver.quit()\n",
    "            if attempt + 1 == MAX_RETRIES:\n",
    "                print(\"Max retries reached. Skipping this page.\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(arr, columns=[\"Links\"])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('choThueMatBangLinks.csv', index=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl links cho thuê đất from nhatot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array to store the links\n",
    "arr = []\n",
    "start_page = 1\n",
    "end_page = 1000\n",
    "\n",
    "# Retry logic\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "for page in range(start_page, end_page + 1):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Initialize WebDriver for each page\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "            url = f\"https://www.nhatot.com/thue-dat?page={page}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # Use explicit wait for better control\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, 'AdItem_adItem__gDDQT')))\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Find all the links with the specified class\n",
    "            a_tags = soup.find_all(\"a\", class_='AdItem_adItem__gDDQT')\n",
    "\n",
    "            # Append the full link to the array\n",
    "            for a in a_tags:\n",
    "                full_link = \"https://www.nhatot.com\" + a['href']\n",
    "                arr.append(full_link)\n",
    "\n",
    "            driver.quit()\n",
    "            break  # Break if the request was successful\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            driver.quit()\n",
    "            if attempt + 1 == MAX_RETRIES:\n",
    "                print(\"Max retries reached. Skipping this page.\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(arr, columns=[\"Links\"])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('choThueDatLinks.csv', index=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl links cho thuê phòng trọ from nhatot.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the array to store the links\n",
    "arr = []\n",
    "start_page = 1\n",
    "end_page = 1000\n",
    "\n",
    "# Retry logic\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "for page in range(start_page, end_page + 1):\n",
    "    for attempt in range(MAX_RETRIES):\n",
    "        try:\n",
    "            # Initialize WebDriver for each page\n",
    "            driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "            url = f\"https://www.nhatot.com/thue-phong-tro?page={page}\"\n",
    "            driver.get(url)\n",
    "\n",
    "            # Use explicit wait for better control\n",
    "            WebDriverWait(driver, 15).until(EC.presence_of_element_located((By.CLASS_NAME, 'AdItem_adItem__gDDQT')))\n",
    "\n",
    "            # Parse the page source with BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Find all the links with the specified class\n",
    "            a_tags = soup.find_all(\"a\", class_='AdItem_adItem__gDDQT')\n",
    "\n",
    "            # Append the full link to the array\n",
    "            for a in a_tags:\n",
    "                full_link = \"https://www.nhatot.com\" + a['href']\n",
    "                arr.append(full_link)\n",
    "\n",
    "            driver.quit()\n",
    "            break  # Break if the request was successful\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            driver.quit()\n",
    "            if attempt + 1 == MAX_RETRIES:\n",
    "                print(\"Max retries reached. Skipping this page.\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "\n",
    "# Create a DataFrame from the array\n",
    "df = pd.DataFrame(arr, columns=[\"Links\"])\n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('choThuePhongTroLinks.csv', index=True)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test lấy dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,85 tỷ\n",
      "Tổ 4, KP Long Khánh 3, Phường Tam Phước, Thành phố Biên Hòa, Đồng Nai\n",
      "Hướng cửa chính: Tây\n",
      "36,32 triệu/m²\n",
      "3 phòng\n",
      "Tây\n",
      "3 phòng\n",
      "3\n",
      "Đã có sổ\n",
      "Nhà mặt phố, mặt tiền\n",
      "Nội thất đầy đủ\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "# Truy cập vào trang web\n",
    "url = 'https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-bien-hoa-dong-nai/119225036.htm#px=SR-stickyad-[PO-1][PL-top]'\n",
    "driver.get(url)\n",
    "\n",
    "# Đợi một chút để trang tải hết nội dung\n",
    "time.sleep(5)\n",
    "\n",
    "# Lấy nội dung của trang\n",
    "page_source = driver.page_source\n",
    "\n",
    "# Đóng trình duyệt\n",
    "driver.quit()\n",
    "\n",
    "# Phân tích cú pháp HTML với BeautifulSoup\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "print(price)\n",
    "\n",
    "address = soup.find_all(\"span\", class_=\"bwq0cbs\")\n",
    "print(address[4].text)\n",
    "\n",
    "price_m2 = soup.find(\"span\", itemprop=\"price_m2\").text\n",
    "rooms = soup.find(\"span\", itemprop=\"rooms\").text\n",
    "toilets = soup.find(\"span\", itemprop=\"toilets\").text\n",
    "direction = soup.find(\"span\", itemprop=\"direction\").text\n",
    "floors = soup.find(\"span\", itemprop=\"floors\").text\n",
    "property_legal_document = soup.find(\"span\", itemprop=\"property_legal_document\").text\n",
    "house_type = soup.find(\"span\", itemprop=\"house_type\").text\n",
    "furnishing_sell = soup.find(\"span\", itemprop=\"furnishing_sell\").text\n",
    "width = soup.find(\"span\", itemprop=\"width\").text\n",
    "length = soup.find(\"span\", itemprop=\"length\").text\n",
    "living_size = soup.find(\"span\", itemprop=\"living_size\").text\n",
    "size = soup.find(\"span\", itemprop=\"size\").text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lấy chi tiết data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy chi tiết data mua bán nhà ở"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed URL 1: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119306902.htm#px=SR-stickyad-[PO-1][PL-top]\n",
      "Processed URL 2: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119223215.htm#px=SR-stickyad-[PO-2][PL-top]\n",
      "Processed URL 3: https://www.nhatot.com/mua-ban-nha-dat-huyen-cu-chi-tp-ho-chi-minh/119266611.htm#px=SR-stickyad-[PO-3][PL-top]\n",
      "Processed URL 4: https://www.nhatot.com/mua-ban-nha-dat-quan-ninh-kieu-can-tho/119204611.htm#px=SR-stickyad-[PO-4][PL-top]\n",
      "Processed URL 5: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119299637.htm#px=SR-stickyad-[PO-5][PL-top]\n",
      "Processed URL 6: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/118706025.htm#px=SR-special_display_ad-[PO-6][PL-default]\n",
      "Processed URL 7: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119319183.htm\n",
      "Processed URL 8: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-bien-hoa-dong-nai/119319181.htm\n",
      "Processed URL 9: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119319178.htm\n",
      "Processed URL 10: https://www.nhatot.com/mua-ban-nha-dat-quan-dong-da-ha-noi/118527145.htm\n",
      "Processed URL 11: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119319166.htm\n",
      "Processed URL 12: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/118672016.htm\n",
      "Processed URL 13: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-ben-tre-ben-tre/119224914.htm#px=SR-special_display_ad-[PO-13][PL-default]\n",
      "Processed URL 14: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119319158.htm\n",
      "Processed URL 15: https://www.nhatot.com/mua-ban-nha-dat-quan-bac-tu-liem-ha-noi/119059912.htm\n",
      "Processed URL 16: https://www.nhatot.com/mua-ban-nha-dat-quan-hai-ba-trung-ha-noi/119319145.htm\n",
      "Processed URL 17: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119143399.htm\n",
      "Processed URL 18: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119319139.htm\n",
      "Processed URL 19: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119268603.htm#px=SR-special_display_ad-[PO-19][PL-default]\n",
      "Processed URL 20: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119319136.htm\n",
      "Processed URL 21: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/117528150.htm#px=SR-special_display_ad-[PO-21][PL-default]\n",
      "Processed URL 22: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/117836478.htm\n",
      "Processed URL 23: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/119319126.htm\n",
      "Processed URL 24: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-dau-mot-binh-duong/119199532.htm#px=SR-special_display_ad-[PO-24][PL-default]\n",
      "Processed URL 25: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119254543.htm\n",
      "Processed URL 26: https://www.nhatot.com/mua-ban-nha-dat-thi-xa-ben-cat-binh-duong/114120310.htm#px=SR-stickyad-[PO-1][PL-top]\n",
      "Processed URL 27: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119215787.htm#px=SR-stickyad-[PO-2][PL-top]\n",
      "Processed URL 28: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/119247509.htm#px=SR-stickyad-[PO-3][PL-top]\n",
      "Processed URL 29: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/118334235.htm#px=SR-stickyad-[PO-4][PL-top]\n",
      "Processed URL 30: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/118694634.htm#px=SR-stickyad-[PO-5][PL-top]\n",
      "Processed URL 31: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-dau-mot-binh-duong/119199532.htm#px=SR-special_display_ad-[PO-6][PL-default]\n",
      "Processed URL 32: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119254543.htm\n",
      "Processed URL 33: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/117731465.htm\n",
      "Processed URL 34: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119125722.htm\n",
      "Processed URL 35: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/110802861.htm\n",
      "Processed URL 36: https://www.nhatot.com/mua-ban-nha-dat-quan-lien-chieu-da-nang/119319123.htm\n",
      "Processed URL 37: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/118905609.htm\n",
      "Processed URL 38: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119319121.htm\n",
      "Processed URL 39: https://www.nhatot.com/mua-ban-nha-dat-quan-ha-dong-ha-noi/118933440.htm\n",
      "Processed URL 40: https://www.nhatot.com/mua-ban-nha-dat-quan-ha-dong-ha-noi/119319113.htm\n",
      "Processed URL 41: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119319110.htm\n",
      "Processed URL 42: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/116782819.htm\n",
      "Processed URL 43: https://www.nhatot.com/mua-ban-nha-dat-quan-thanh-xuan-ha-noi/118949217.htm\n",
      "Processed URL 44: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/118823549.htm\n",
      "Processed URL 45: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/118768977.htm\n",
      "Processed URL 46: https://www.nhatot.com/mua-ban-nha-dat-huyen-can-giuoc-long-an/118725363.htm\n",
      "Processed URL 47: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-pleiku-gia-lai/113549325.htm#px=SR-special_display_ad-[PO-22][PL-default]\n",
      "Processed URL 48: https://www.nhatot.com/mua-ban-nha-dat-quan-3-tp-ho-chi-minh/116540319.htm\n",
      "Processed URL 49: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/117396063.htm#px=SR-special_display_ad-[PO-24][PL-default]\n",
      "Processed URL 50: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-pleiku-gia-lai/112897252.htm#px=SR-special_display_ad-[PO-25][PL-default]\n",
      "Processed URL 51: https://www.nhatot.com/mua-ban-nha-dat-huyen-can-giuoc-long-an/118725363.htm\n",
      "Processed URL 52: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-pleiku-gia-lai/113549325.htm#px=SR-special_display_ad-[PO-2][PL-default]\n",
      "Processed URL 53: https://www.nhatot.com/mua-ban-nha-dat-quan-3-tp-ho-chi-minh/116540319.htm\n",
      "Processed URL 54: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/117396063.htm#px=SR-special_display_ad-[PO-4][PL-default]\n",
      "Processed URL 55: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-pleiku-gia-lai/112897252.htm#px=SR-special_display_ad-[PO-5][PL-default]\n",
      "Processed URL 56: https://www.nhatot.com/mua-ban-nha-dat-quan-1-tp-ho-chi-minh/119319076.htm\n",
      "Processed URL 57: https://www.nhatot.com/mua-ban-nha-dat-quan-thanh-khe-da-nang/119319075.htm\n",
      "Processed URL 58: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-di-an-binh-duong/119319074.htm\n",
      "Processed URL 59: https://www.nhatot.com/mua-ban-nha-dat-quan-ninh-kieu-can-tho/118459432.htm\n",
      "Processed URL 60: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/119186378.htm\n",
      "Processed URL 61: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/117113294.htm\n",
      "Processed URL 62: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-buon-ma-thuot-dak-lak/119319067.htm\n",
      "Processed URL 63: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/118905081.htm#px=SR-special_display_ad-[PO-13][PL-default]\n",
      "Processed URL 64: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119100031.htm\n",
      "Processed URL 65: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/119246843.htm\n",
      "Processed URL 66: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-pleiku-gia-lai/111709677.htm#px=SR-special_display_ad-[PO-16][PL-default]\n",
      "Error processing URL https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119319057.htm: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x004CD933+25811]\n",
      "\t(No symbol) [0x0045E314]\n",
      "\t(No symbol) [0x00352523]\n",
      "\t(No symbol) [0x00397483]\n",
      "\t(No symbol) [0x0039765B]\n",
      "\t(No symbol) [0x003D6BA2]\n",
      "\t(No symbol) [0x003BAD74]\n",
      "\t(No symbol) [0x003D46F0]\n",
      "\t(No symbol) [0x003BAAC6]\n",
      "\t(No symbol) [0x0038BEFD]\n",
      "\t(No symbol) [0x0038C8FD]\n",
      "\tGetHandleVerifier [0x0079F143+2981091]\n",
      "\tGetHandleVerifier [0x007F2FF9+3324825]\n",
      "\tGetHandleVerifier [0x0055B32F+605903]\n",
      "\tGetHandleVerifier [0x00562CBC+637020]\n",
      "\t(No symbol) [0x00466F4D]\n",
      "\t(No symbol) [0x00463DD8]\n",
      "\t(No symbol) [0x00463F75]\n",
      "\t(No symbol) [0x00456406]\n",
      "\tBaseThreadInitThunk [0x75A4FCC9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x778C80CE+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x778C809E+238]\n",
      "\n",
      "Processed URL 67: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119319057.htm\n",
      "Processed URL 68: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119171982.htm#px=SR-special_display_ad-[PO-18][PL-default]\n",
      "Processed URL 69: https://www.nhatot.com/mua-ban-nha-dat-huyen-cu-kuin-dak-lak/116603492.htm\n",
      "Processed URL 70: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/119319046.htm\n",
      "Processed URL 71: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/119319046.htm\n",
      "Processed URL 72: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/115932697.htm\n",
      "Processed URL 73: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/118824977.htm\n",
      "Processed URL 74: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/117962939.htm\n",
      "Processed URL 75: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/115933113.htm\n",
      "Processed URL 76: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-bien-hoa-dong-nai/119319033.htm\n",
      "Processed URL 77: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119306519.htm\n",
      "Processed URL 78: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119224775.htm\n",
      "Processed URL 79: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/119319026.htm\n",
      "Processed URL 80: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/118526803.htm\n",
      "Processed URL 81: https://www.nhatot.com/mua-ban-nha-dat-quan-1-tp-ho-chi-minh/118769840.htm\n",
      "Processed URL 82: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119298262.htm\n",
      "Processed URL 83: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119319020.htm\n",
      "Processed URL 84: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/119319017.htm\n",
      "Processed URL 85: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/119268918.htm\n",
      "Processed URL 86: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119239231.htm\n",
      "Processed URL 87: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/118762480.htm\n",
      "Processed URL 88: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119110780.htm\n",
      "Processed URL 89: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119319010.htm\n",
      "Processed URL 90: https://www.nhatot.com/mua-ban-nha-dat-quan-ninh-kieu-can-tho/119205935.htm\n",
      "Processed URL 91: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119319010.htm\n",
      "Processed URL 92: https://www.nhatot.com/mua-ban-nha-dat-quan-ninh-kieu-can-tho/119205935.htm\n",
      "Processed URL 93: https://www.nhatot.com/mua-ban-nha-dat-quan-5-tp-ho-chi-minh/119319001.htm#px=SR-special_display_ad-[PO-3][PL-default]\n",
      "Processed URL 94: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119319003.htm\n",
      "Processed URL 95: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/118649823.htm\n",
      "Processed URL 96: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119186899.htm\n",
      "Processed URL 97: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119000448.htm\n",
      "Processed URL 98: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118774026.htm\n",
      "Processed URL 99: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/119253040.htm\n",
      "Processed URL 100: https://www.nhatot.com/mua-ban-nha-dat-quan-cau-giay-ha-noi/119318980.htm\n",
      "Processed URL 101: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119270064.htm\n",
      "Processed URL 102: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119034888.htm\n",
      "Processed URL 103: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119293368.htm#px=SR-special_display_ad-[PO-13][PL-default]\n",
      "Processed URL 104: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318711.htm\n",
      "Processed URL 105: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318961.htm\n",
      "Processed URL 106: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119110266.htm\n",
      "Processed URL 107: https://www.nhatot.com/mua-ban-nha-dat-quan-ha-dong-ha-noi/119318953.htm\n",
      "Processed URL 108: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/118263981.htm\n",
      "Processed URL 109: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119246856.htm#px=SR-special_display_ad-[PO-19][PL-default]\n",
      "Processed URL 110: https://www.nhatot.com/mua-ban-nha-dat-quan-4-tp-ho-chi-minh/119318940.htm\n",
      "Processed URL 111: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/119253040.htm\n",
      "Processed URL 112: https://www.nhatot.com/mua-ban-nha-dat-quan-cau-giay-ha-noi/119318980.htm\n",
      "Processed URL 113: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119270064.htm\n",
      "Processed URL 114: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119034888.htm\n",
      "Processed URL 115: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119293368.htm#px=SR-special_display_ad-[PO-5][PL-default]\n",
      "Processed URL 116: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318711.htm\n",
      "Processed URL 117: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318961.htm\n",
      "Processed URL 118: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119110266.htm\n",
      "Processed URL 119: https://www.nhatot.com/mua-ban-nha-dat-quan-ha-dong-ha-noi/119318953.htm\n",
      "Processed URL 120: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/118263981.htm\n",
      "Processed URL 121: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119246856.htm#px=SR-special_display_ad-[PO-11][PL-default]\n",
      "Processed URL 122: https://www.nhatot.com/mua-ban-nha-dat-quan-4-tp-ho-chi-minh/119318940.htm\n",
      "Processed URL 123: https://www.nhatot.com/mua-ban-nha-dat-huyen-can-giuoc-long-an/118232853.htm\n",
      "Processed URL 124: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119293334.htm\n",
      "Processed URL 125: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/117117210.htm\n",
      "Processed URL 126: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119318935.htm\n",
      "Processed URL 127: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/117157395.htm\n",
      "Processed URL 128: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/117598938.htm\n",
      "Processed URL 129: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318895.htm\n",
      "Processed URL 130: https://www.nhatot.com/mua-ban-nha-dat-quan-cai-rang-can-tho/116326889.htm\n",
      "Processed URL 131: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/117598938.htm\n",
      "Processed URL 132: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318895.htm\n",
      "Processed URL 133: https://www.nhatot.com/mua-ban-nha-dat-quan-cai-rang-can-tho/116326889.htm\n",
      "Processed URL 134: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119318920.htm\n",
      "Processed URL 135: https://www.nhatot.com/mua-ban-nha-dat-quan-4-tp-ho-chi-minh/119318917.htm\n",
      "Processed URL 136: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/116653507.htm\n",
      "Processed URL 137: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119293245.htm#px=SR-special_display_ad-[PO-7][PL-default]\n",
      "Processed URL 138: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/117972719.htm\n",
      "Processed URL 139: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/117400019.htm#px=SR-special_display_ad-[PO-9][PL-default]\n",
      "Processed URL 140: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/118991296.htm\n",
      "Processed URL 141: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119318909.htm\n",
      "Processed URL 142: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119318908.htm\n",
      "Processed URL 143: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318905.htm\n",
      "Processed URL 144: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119255373.htm\n",
      "Processed URL 145: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/114386036.htm\n",
      "Processed URL 146: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119265863.htm\n",
      "Processed URL 147: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/118537378.htm\n",
      "Processed URL 148: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/119318889.htm\n",
      "Processed URL 149: https://www.nhatot.com/mua-ban-nha-dat-quan-ninh-kieu-can-tho/119318879.htm\n",
      "Processed URL 150: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/117324009.htm\n",
      "Processed URL 151: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/114386036.htm\n",
      "Processed URL 152: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119265863.htm\n",
      "Processed URL 153: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/118537378.htm\n",
      "Processed URL 154: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/119318889.htm\n",
      "Processed URL 155: https://www.nhatot.com/mua-ban-nha-dat-quan-ninh-kieu-can-tho/119318879.htm\n",
      "Processed URL 156: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/117324009.htm\n",
      "Processed URL 157: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/118880253.htm#px=SR-special_display_ad-[PO-7][PL-default]\n",
      "Processed URL 158: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119144707.htm\n",
      "Processed URL 159: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/118680177.htm\n",
      "Processed URL 160: https://www.nhatot.com/mua-ban-nha-dat-huyen-nha-be-tp-ho-chi-minh/116363140.htm\n",
      "Processed URL 161: https://www.nhatot.com/mua-ban-nha-dat-quan-ha-dong-ha-noi/119318870.htm\n",
      "Processed URL 162: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/114502874.htm#px=SR-special_display_ad-[PO-12][PL-default]\n",
      "Processed URL 163: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-di-an-binh-duong/119318865.htm\n",
      "Processed URL 164: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/118651390.htm\n",
      "Processed URL 165: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118961323.htm\n",
      "Processed URL 166: https://www.nhatot.com/mua-ban-nha-dat-quan-bac-tu-liem-ha-noi/119318850.htm\n",
      "Processed URL 167: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-di-an-binh-duong/119318845.htm\n",
      "Processed URL 168: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119293267.htm\n",
      "Processed URL 169: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/117908300.htm\n",
      "Processed URL 170: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/118857124.htm\n",
      "Processed URL 171: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118961323.htm\n",
      "Processed URL 172: https://www.nhatot.com/mua-ban-nha-dat-quan-bac-tu-liem-ha-noi/119318850.htm\n",
      "Processed URL 173: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-di-an-binh-duong/119318845.htm\n",
      "Processed URL 174: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119293267.htm\n",
      "Processed URL 175: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/117908300.htm\n",
      "Processed URL 176: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/118857124.htm\n",
      "Processed URL 177: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118312609.htm\n",
      "Processed URL 178: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/118535828.htm\n",
      "Processed URL 179: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/119318826.htm\n",
      "Processed URL 180: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119318825.htm\n",
      "Processed URL 181: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/118812500.htm\n",
      "Processed URL 182: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318813.htm#px=SR-special_display_ad-[PO-12][PL-default]\n",
      "Processed URL 183: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/118718733.htm\n",
      "Processed URL 184: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119172086.htm#px=SR-special_display_ad-[PO-14][PL-default]\n",
      "Processed URL 185: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/117241415.htm\n",
      "Processed URL 186: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/116122496.htm#px=SR-special_display_ad-[PO-16][PL-default]\n",
      "Processed URL 187: https://www.nhatot.com/mua-ban-nha-dat-quan-ha-dong-ha-noi/119318794.htm\n",
      "Processed URL 188: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/115928831.htm#px=SR-special_display_ad-[PO-18][PL-default]\n",
      "Processed URL 189: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/116783267.htm\n",
      "Processed URL 190: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318785.htm\n",
      "Processed URL 191: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/115928831.htm#px=SR-special_display_ad-[PO-1][PL-default]\n",
      "Processed URL 192: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/116783267.htm\n",
      "Processed URL 193: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318785.htm\n",
      "Processed URL 194: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/119318784.htm\n",
      "Processed URL 195: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119318782.htm#px=SR-special_display_ad-[PO-5][PL-default]\n",
      "Processed URL 196: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/118285374.htm\n",
      "Processed URL 197: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/117055345.htm\n",
      "Processed URL 198: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/118399359.htm\n",
      "Processed URL 199: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/117827573.htm\n",
      "Processed URL 200: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/115934354.htm\n",
      "Processed URL 201: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/117838020.htm\n",
      "Processed URL 202: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119304015.htm\n",
      "Processed URL 203: https://www.nhatot.com/mua-ban-nha-dat-quan-cau-giay-ha-noi/119318764.htm\n",
      "Processed URL 204: https://www.nhatot.com/mua-ban-nha-dat-quan-3-tp-ho-chi-minh/116156416.htm\n",
      "Processed URL 205: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/119318762.htm\n",
      "Processed URL 206: https://www.nhatot.com/mua-ban-nha-dat-quan-dong-da-ha-noi/119318761.htm\n",
      "Processed URL 207: https://www.nhatot.com/mua-ban-nha-dat-quan-1-tp-ho-chi-minh/115744058.htm\n",
      "Processed URL 208: https://www.nhatot.com/mua-ban-nha-dat-quan-long-bien-ha-noi/119318756.htm\n",
      "Processed URL 209: https://www.nhatot.com/mua-ban-nha-dat-huyen-go-dau-tay-ninh/119318497.htm\n",
      "Processed URL 210: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119312766.htm#px=SR-special_display_ad-[PO-20][PL-default]\n",
      "Processed URL 211: https://www.nhatot.com/mua-ban-nha-dat-quan-1-tp-ho-chi-minh/115744058.htm\n",
      "Processed URL 212: https://www.nhatot.com/mua-ban-nha-dat-quan-long-bien-ha-noi/119318756.htm\n",
      "Processed URL 213: https://www.nhatot.com/mua-ban-nha-dat-huyen-go-dau-tay-ninh/119318497.htm\n",
      "Processed URL 214: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119312766.htm#px=SR-special_display_ad-[PO-4][PL-default]\n",
      "Processed URL 215: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/115933367.htm\n",
      "Processed URL 216: https://www.nhatot.com/mua-ban-nha-dat-quan-1-tp-ho-chi-minh/115795201.htm\n",
      "Processed URL 217: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/115942234.htm\n",
      "Processed URL 218: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/118037874.htm\n",
      "Processed URL 219: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119303303.htm\n",
      "Processed URL 220: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318741.htm\n",
      "Processed URL 221: https://www.nhatot.com/mua-ban-nha-dat-quan-cai-rang-can-tho/118622161.htm\n",
      "Processed URL 222: https://www.nhatot.com/mua-ban-nha-dat-quan-ninh-kieu-can-tho/118469279.htm\n",
      "Processed URL 223: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/119318732.htm\n",
      "Processed URL 224: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119318728.htm\n",
      "Processed URL 225: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119318730.htm\n",
      "Processed URL 226: https://www.nhatot.com/mua-ban-nha-dat-huyen-chuong-my-ha-noi/119318727.htm\n",
      "Processed URL 227: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119318724.htm\n",
      "Processed URL 228: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/118410532.htm\n",
      "Processed URL 229: https://www.nhatot.com/mua-ban-nha-dat-huyen-hoc-mon-tp-ho-chi-minh/119240480.htm\n",
      "Processed URL 230: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119318710.htm\n",
      "Processed URL 231: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119318724.htm\n",
      "Processed URL 232: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/118410532.htm\n",
      "Processed URL 233: https://www.nhatot.com/mua-ban-nha-dat-huyen-hoc-mon-tp-ho-chi-minh/119240480.htm\n",
      "Processed URL 234: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119318710.htm\n",
      "Processed URL 235: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/117331712.htm\n",
      "Processed URL 236: https://www.nhatot.com/mua-ban-nha-dat-huyen-hoc-mon-tp-ho-chi-minh/118557300.htm\n",
      "Processed URL 237: https://www.nhatot.com/mua-ban-nha-dat-quan-tay-ho-ha-noi/119262228.htm\n",
      "Processed URL 238: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/116836101.htm\n",
      "Processed URL 239: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/116132847.htm#px=SR-special_display_ad-[PO-9][PL-default]\n",
      "Processed URL 240: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/119318701.htm\n",
      "Processed URL 241: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119237091.htm\n",
      "Processed URL 242: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/118601243.htm\n",
      "Processed URL 243: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/119318688.htm\n",
      "Error processing URL https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119216653.htm: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x004CD933+25811]\n",
      "\t(No symbol) [0x0045E314]\n",
      "\t(No symbol) [0x00352523]\n",
      "\t(No symbol) [0x00397483]\n",
      "\t(No symbol) [0x0039765B]\n",
      "\t(No symbol) [0x003D6BA2]\n",
      "\t(No symbol) [0x003BAD74]\n",
      "\t(No symbol) [0x003D46F0]\n",
      "\t(No symbol) [0x003BAAC6]\n",
      "\t(No symbol) [0x0038BEFD]\n",
      "\t(No symbol) [0x0038C8FD]\n",
      "\tGetHandleVerifier [0x0079F143+2981091]\n",
      "\tGetHandleVerifier [0x007F2FF9+3324825]\n",
      "\tGetHandleVerifier [0x0055B32F+605903]\n",
      "\tGetHandleVerifier [0x00562CBC+637020]\n",
      "\t(No symbol) [0x00466F4D]\n",
      "\t(No symbol) [0x00463DD8]\n",
      "\t(No symbol) [0x00463F75]\n",
      "\t(No symbol) [0x00456406]\n",
      "\tBaseThreadInitThunk [0x75A4FCC9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x778C80CE+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x778C809E+238]\n",
      "\n",
      "Processed URL 244: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119216653.htm\n",
      "Processed URL 245: https://www.nhatot.com/mua-ban-nha-dat-huyen-hoai-duc-ha-noi/119318680.htm\n",
      "Processed URL 246: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/92036551.htm\n",
      "Processed URL 247: https://www.nhatot.com/mua-ban-nha-dat-huyen-bau-bang-binh-duong/119252642.htm\n",
      "Processed URL 248: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119318677.htm\n",
      "Processed URL 249: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/118946975.htm\n",
      "Processed URL 250: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/114387545.htm\n",
      "Processed URL 251: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/114387545.htm\n",
      "Processed URL 252: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318660.htm\n",
      "Processed URL 253: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119164519.htm\n",
      "Processed URL 254: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-gia-nghia-dak-nong/119318644.htm\n",
      "Processed URL 255: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/116521766.htm#px=SR-special_display_ad-[PO-5][PL-default]\n",
      "Processed URL 256: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/117974469.htm\n",
      "Processed URL 257: https://www.nhatot.com/mua-ban-nha-dat-thi-xa-tan-uyen-binh-duong/116818870.htm#px=SR-special_display_ad-[PO-7][PL-default]\n",
      "Processed URL 258: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119293122.htm#px=SR-special_display_ad-[PO-8][PL-default]\n",
      "Processed URL 259: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318638.htm\n",
      "Processed URL 260: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-dau-mot-binh-duong/119199012.htm\n",
      "Processed URL 261: https://www.nhatot.com/mua-ban-nha-dat-quan-ba-dinh-ha-noi/119268078.htm\n",
      "Processed URL 262: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318627.htm\n",
      "Processed URL 263: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119293105.htm#px=SR-special_display_ad-[PO-13][PL-default]\n",
      "Processed URL 264: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/110802862.htm\n",
      "Processed URL 265: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/115272322.htm\n",
      "Processed URL 266: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119138680.htm\n",
      "Processed URL 267: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119318611.htm\n",
      "Processed URL 268: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/116502990.htm\n",
      "Processed URL 269: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/117796089.htm\n",
      "Processed URL 270: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118823899.htm#px=SR-special_display_ad-[PO-20][PL-default]\n",
      "Processed URL 271: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119164519.htm\n",
      "Processed URL 272: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-gia-nghia-dak-nong/119318644.htm\n",
      "Processed URL 273: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/116521766.htm#px=SR-special_display_ad-[PO-3][PL-default]\n",
      "Processed URL 274: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/117974469.htm\n",
      "Processed URL 275: https://www.nhatot.com/mua-ban-nha-dat-thi-xa-tan-uyen-binh-duong/116818870.htm#px=SR-special_display_ad-[PO-5][PL-default]\n",
      "Processed URL 276: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119293122.htm#px=SR-special_display_ad-[PO-6][PL-default]\n",
      "Processed URL 277: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318638.htm\n",
      "Processed URL 278: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-dau-mot-binh-duong/119199012.htm\n",
      "Processed URL 279: https://www.nhatot.com/mua-ban-nha-dat-quan-ba-dinh-ha-noi/119268078.htm\n",
      "Processed URL 280: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318627.htm\n",
      "Processed URL 281: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119293105.htm#px=SR-special_display_ad-[PO-11][PL-default]\n",
      "Processed URL 282: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/110802862.htm\n",
      "Processed URL 283: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/115272322.htm\n",
      "Processed URL 284: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119138680.htm\n",
      "Processed URL 285: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119318611.htm\n",
      "Processed URL 286: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/116502990.htm\n",
      "Processed URL 287: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/117796089.htm\n",
      "Processed URL 288: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118823899.htm#px=SR-special_display_ad-[PO-18][PL-default]\n",
      "Processed URL 289: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119142362.htm#px=SR-special_display_ad-[PO-19][PL-default]\n",
      "Processed URL 290: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/119318600.htm\n",
      "Processed URL 291: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/119318600.htm\n",
      "Processed URL 292: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119252232.htm\n",
      "Processed URL 293: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/118760984.htm\n",
      "Processed URL 294: https://www.nhatot.com/mua-ban-nha-dat-quan-ha-dong-ha-noi/119318584.htm\n",
      "Processed URL 295: https://www.nhatot.com/mua-ban-nha-dat-quan-thanh-xuan-ha-noi/119318581.htm\n",
      "Processed URL 296: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119097491.htm\n",
      "Processed URL 297: https://www.nhatot.com/mua-ban-nha-dat-quan-hai-ba-trung-ha-noi/117598134.htm\n",
      "Processed URL 298: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/116386947.htm\n",
      "Processed URL 299: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/116883615.htm\n",
      "Processed URL 300: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/118064646.htm\n",
      "Processed URL 301: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-bien-hoa-dong-nai/119148499.htm\n",
      "Processed URL 302: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119181363.htm\n",
      "Processed URL 303: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/110400619.htm\n",
      "Processed URL 304: https://www.nhatot.com/mua-ban-nha-dat-quan-son-tra-da-nang/119247327.htm\n",
      "Processed URL 305: https://www.nhatot.com/mua-ban-nha-dat-huyen-nhon-trach-dong-nai/118434357.htm\n",
      "Processed URL 306: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/112879702.htm\n",
      "Processed URL 307: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118728203.htm\n",
      "Processed URL 308: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/118701706.htm\n",
      "Processed URL 309: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/118883218.htm\n",
      "Processed URL 310: https://www.nhatot.com/mua-ban-nha-dat-thi-xa-tan-uyen-binh-duong/119318556.htm\n",
      "Processed URL 311: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/118883218.htm\n",
      "Processed URL 312: https://www.nhatot.com/mua-ban-nha-dat-thi-xa-tan-uyen-binh-duong/119318556.htm\n",
      "Processed URL 313: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/117696025.htm\n",
      "Processed URL 314: https://www.nhatot.com/mua-ban-nha-dat-huyen-nhon-trach-dong-nai/117497443.htm\n",
      "Processed URL 315: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-bien-hoa-dong-nai/119318552.htm\n",
      "Processed URL 316: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118493463.htm\n",
      "Processed URL 317: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/116685980.htm\n",
      "Processed URL 318: https://www.nhatot.com/mua-ban-nha-dat-quan-hai-ba-trung-ha-noi/118773723.htm#px=SR-special_display_ad-[PO-8][PL-default]\n",
      "Processed URL 319: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/118639790.htm\n",
      "Processed URL 320: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/107703285.htm\n",
      "Processed URL 321: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/117852459.htm\n",
      "Processed URL 322: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119124308.htm\n",
      "Processed URL 323: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119318537.htm\n",
      "Processed URL 324: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/115941941.htm#px=SR-special_display_ad-[PO-14][PL-default]\n",
      "Processed URL 325: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119247582.htm\n",
      "Processed URL 326: https://www.nhatot.com/mua-ban-nha-dat-quan-11-tp-ho-chi-minh/119001676.htm\n",
      "Processed URL 327: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/107080009.htm\n",
      "Processed URL 328: https://www.nhatot.com/mua-ban-nha-dat-quan-ha-dong-ha-noi/119318534.htm\n",
      "Processed URL 329: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/119318533.htm\n",
      "Processed URL 330: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/118104136.htm\n",
      "Processed URL 331: https://www.nhatot.com/mua-ban-nha-dat-quan-ha-dong-ha-noi/119318534.htm\n",
      "Processed URL 332: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/119318533.htm\n",
      "Processed URL 333: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/118104136.htm\n",
      "Processed URL 334: https://www.nhatot.com/mua-ban-nha-dat-quan-4-tp-ho-chi-minh/119318530.htm\n",
      "Processed URL 335: https://www.nhatot.com/mua-ban-nha-dat-quan-dong-da-ha-noi/117384519.htm#px=SR-special_display_ad-[PO-5][PL-default]\n",
      "Processed URL 336: https://www.nhatot.com/mua-ban-nha-dat-quan-cai-rang-can-tho/118962357.htm\n",
      "Processed URL 337: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318523.htm\n",
      "Processed URL 338: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119318516.htm\n",
      "Error processing URL https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119318515.htm: Message: \n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x004CD933+25811]\n",
      "\t(No symbol) [0x0045E314]\n",
      "\t(No symbol) [0x00352523]\n",
      "\t(No symbol) [0x00397483]\n",
      "\t(No symbol) [0x0039765B]\n",
      "\t(No symbol) [0x003D6BA2]\n",
      "\t(No symbol) [0x003BAD74]\n",
      "\t(No symbol) [0x003D46F0]\n",
      "\t(No symbol) [0x003BAAC6]\n",
      "\t(No symbol) [0x0038BEFD]\n",
      "\t(No symbol) [0x0038C8FD]\n",
      "\tGetHandleVerifier [0x0079F143+2981091]\n",
      "\tGetHandleVerifier [0x007F2FF9+3324825]\n",
      "\tGetHandleVerifier [0x0055B32F+605903]\n",
      "\tGetHandleVerifier [0x00562CBC+637020]\n",
      "\t(No symbol) [0x00466F4D]\n",
      "\t(No symbol) [0x00463DD8]\n",
      "\t(No symbol) [0x00463F75]\n",
      "\t(No symbol) [0x00456406]\n",
      "\tBaseThreadInitThunk [0x75A4FCC9+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x778C80CE+286]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x778C809E+238]\n",
      "\n",
      "Processed URL 339: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119318515.htm\n",
      "Processed URL 340: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119028765.htm#px=SR-special_display_ad-[PO-10][PL-default]\n",
      "Processed URL 341: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/118792044.htm\n",
      "Processed URL 342: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/118957065.htm\n",
      "Processed URL 343: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/118042462.htm\n",
      "Processed URL 344: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318504.htm\n",
      "Processed URL 345: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119286223.htm\n",
      "Processed URL 346: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/116314174.htm\n",
      "Processed URL 347: https://www.nhatot.com/mua-ban-nha-dat-quan-cai-rang-can-tho/119202352.htm\n",
      "Processed URL 348: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119303719.htm\n",
      "Processed URL 349: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118509976.htm\n",
      "Processed URL 350: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119066884.htm#px=SR-special_display_ad-[PO-20][PL-default]\n",
      "Processed URL 351: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/116314174.htm\n",
      "Processed URL 352: https://www.nhatot.com/mua-ban-nha-dat-quan-cai-rang-can-tho/119202352.htm\n",
      "Processed URL 353: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119303719.htm\n",
      "Processed URL 354: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/118509976.htm\n",
      "Processed URL 355: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119066884.htm#px=SR-special_display_ad-[PO-5][PL-default]\n",
      "Processed URL 356: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119042559.htm\n",
      "Processed URL 357: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/117575495.htm\n",
      "Processed URL 358: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119199195.htm#px=SR-special_display_ad-[PO-8][PL-default]\n",
      "Processed URL 359: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/117747784.htm\n",
      "Processed URL 360: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119259589.htm#px=SR-special_display_ad-[PO-10][PL-default]\n",
      "Processed URL 361: https://www.nhatot.com/mua-ban-nha-dat-quan-3-tp-ho-chi-minh/118981187.htm\n",
      "Processed URL 362: https://www.nhatot.com/mua-ban-nha-dat-huyen-chuong-my-ha-noi/119318485.htm\n",
      "Processed URL 363: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318481.htm\n",
      "Processed URL 364: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/119318477.htm\n",
      "Processed URL 365: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/117297915.htm\n",
      "Processed URL 366: https://www.nhatot.com/mua-ban-nha-dat-quan-lien-chieu-da-nang/119318472.htm#px=SR-special_display_ad-[PO-16][PL-default]\n",
      "Processed URL 367: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119229342.htm#px=SR-special_display_ad-[PO-17][PL-default]\n",
      "Processed URL 368: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318471.htm\n",
      "Processed URL 369: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119318467.htm\n",
      "Processed URL 370: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119233990.htm\n",
      "Processed URL 371: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119042559.htm\n",
      "Processed URL 372: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/117575495.htm\n",
      "Processed URL 373: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119199195.htm#px=SR-special_display_ad-[PO-3][PL-default]\n",
      "Processed URL 374: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/117747784.htm\n",
      "Processed URL 375: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119259589.htm#px=SR-special_display_ad-[PO-5][PL-default]\n",
      "Processed URL 376: https://www.nhatot.com/mua-ban-nha-dat-quan-3-tp-ho-chi-minh/118981187.htm\n",
      "Processed URL 377: https://www.nhatot.com/mua-ban-nha-dat-huyen-chuong-my-ha-noi/119318485.htm\n",
      "Processed URL 378: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318481.htm\n",
      "Processed URL 379: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/119318477.htm\n",
      "Processed URL 380: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/117297915.htm\n",
      "Processed URL 381: https://www.nhatot.com/mua-ban-nha-dat-quan-lien-chieu-da-nang/119318472.htm#px=SR-special_display_ad-[PO-11][PL-default]\n",
      "Processed URL 382: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119229342.htm#px=SR-special_display_ad-[PO-12][PL-default]\n",
      "Processed URL 383: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318471.htm\n",
      "Processed URL 384: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119318467.htm\n",
      "Processed URL 385: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119233990.htm\n",
      "Processed URL 386: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119045243.htm\n",
      "Processed URL 387: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/117584531.htm\n",
      "Processed URL 388: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119318453.htm#px=SR-special_display_ad-[PO-18][PL-default]\n",
      "Processed URL 389: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-di-an-binh-duong/119094160.htm#px=SR-special_display_ad-[PO-19][PL-default]\n",
      "Processed URL 390: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thuy-can-tho/119318429.htm\n",
      "Processed URL 391: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119318425.htm\n",
      "Processed URL 392: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/119318424.htm\n",
      "Processed URL 393: https://www.nhatot.com/mua-ban-nha-dat-thi-xa-ben-cat-binh-duong/119253683.htm\n",
      "Processed URL 394: https://www.nhatot.com/mua-ban-nha-dat-quan-bac-tu-liem-ha-noi/119318417.htm\n",
      "Processed URL 395: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119247908.htm\n",
      "Processed URL 396: https://www.nhatot.com/mua-ban-nha-dat-huyen-can-giuoc-long-an/118779988.htm\n",
      "Processed URL 397: https://www.nhatot.com/mua-ban-nha-dat-huyen-cu-chi-tp-ho-chi-minh/112978739.htm\n",
      "Processed URL 398: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119318391.htm\n",
      "Processed URL 399: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/119292906.htm\n",
      "Processed URL 400: https://www.nhatot.com/mua-ban-nha-dat-quan-5-tp-ho-chi-minh/118743331.htm\n",
      "Processed URL 401: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/117292163.htm#px=SR-special_display_ad-[PO-11][PL-default]\n",
      "Processed URL 402: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-di-an-binh-duong/118998984.htm\n",
      "Processed URL 403: https://www.nhatot.com/mua-ban-nha-dat-quan-11-tp-ho-chi-minh/119318379.htm\n",
      "Processed URL 404: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-bien-hoa-dong-nai/119318374.htm#px=SR-special_display_ad-[PO-14][PL-default]\n",
      "Processed URL 405: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/119292883.htm#px=SR-special_display_ad-[PO-15][PL-default]\n",
      "Processed URL 406: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119318364.htm\n",
      "Processed URL 407: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/117477325.htm\n",
      "Processed URL 408: https://www.nhatot.com/mua-ban-nha-dat-huyen-hoa-vang-da-nang/119318361.htm\n",
      "Processed URL 409: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318359.htm\n",
      "Processed URL 410: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119079138.htm\n",
      "Processed URL 411: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119079138.htm\n",
      "Processed URL 412: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119318351.htm\n",
      "Processed URL 413: https://www.nhatot.com/mua-ban-nha-dat-huyen-nha-be-tp-ho-chi-minh/118226888.htm\n",
      "Processed URL 414: https://www.nhatot.com/mua-ban-nha-dat-quan-1-tp-ho-chi-minh/119228911.htm\n",
      "Processed URL 415: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thuan-an-binh-duong/119318339.htm\n",
      "Processed URL 416: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119318337.htm\n",
      "Processed URL 417: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119318332.htm#px=SR-special_display_ad-[PO-7][PL-default]\n",
      "Processed URL 418: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-di-an-binh-duong/119318330.htm\n",
      "Processed URL 419: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/118625128.htm\n",
      "Processed URL 420: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/110802864.htm\n",
      "Processed URL 421: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119293300.htm#px=SR-special_display_ad-[PO-11][PL-default]\n",
      "Processed URL 422: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119304433.htm#px=SR-special_display_ad-[PO-12][PL-default]\n",
      "Processed URL 423: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-di-an-binh-duong/119318325.htm\n",
      "Processed URL 424: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/118390165.htm#px=SR-special_display_ad-[PO-14][PL-default]\n",
      "Processed URL 425: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/115507349.htm#px=SR-special_display_ad-[PO-15][PL-default]\n",
      "Processed URL 426: https://www.nhatot.com/mua-ban-nha-dat-quan-long-bien-ha-noi/119318300.htm#px=SR-special_display_ad-[PO-16][PL-default]\n",
      "Processed URL 427: https://www.nhatot.com/mua-ban-nha-dat-quan-cau-giay-ha-noi/119318298.htm\n",
      "Processed URL 428: https://www.nhatot.com/mua-ban-nha-dat-quan-10-tp-ho-chi-minh/119318297.htm\n",
      "Processed URL 429: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/118131397.htm\n",
      "Processed URL 430: https://www.nhatot.com/mua-ban-nha-dat-quan-cam-le-da-nang/119267805.htm\n",
      "Processed URL 431: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/118131397.htm\n",
      "Processed URL 432: https://www.nhatot.com/mua-ban-nha-dat-quan-cam-le-da-nang/119267805.htm\n",
      "Processed URL 433: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119096321.htm\n",
      "Processed URL 434: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119318276.htm\n",
      "Processed URL 435: https://www.nhatot.com/mua-ban-nha-dat-quan-hoang-mai-ha-noi/118532676.htm\n",
      "Processed URL 436: https://www.nhatot.com/mua-ban-nha-dat-huyen-nha-be-tp-ho-chi-minh/118733571.htm\n",
      "Processed URL 437: https://www.nhatot.com/mua-ban-nha-dat-quan-10-tp-ho-chi-minh/105827899.htm\n",
      "Processed URL 438: https://www.nhatot.com/mua-ban-nha-dat-quan-ninh-kieu-can-tho/119318253.htm\n",
      "Processed URL 439: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/114582403.htm\n",
      "Processed URL 440: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/114287061.htm\n",
      "Processed URL 441: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/118142082.htm\n",
      "Processed URL 442: https://www.nhatot.com/mua-ban-nha-dat-huyen-nha-be-tp-ho-chi-minh/118665412.htm\n",
      "Processed URL 443: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/116610345.htm\n",
      "Processed URL 444: https://www.nhatot.com/mua-ban-nha-dat-huyen-bac-binh-binh-thuan/118918346.htm\n",
      "Processed URL 445: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/118142227.htm\n",
      "Processed URL 446: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/118143176.htm\n",
      "Processed URL 447: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119247053.htm\n",
      "Processed URL 448: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318240.htm\n",
      "Processed URL 449: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/116610842.htm\n",
      "Processed URL 450: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/118388191.htm\n",
      "Processed URL 451: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-tan-an-long-an/118842418.htm\n",
      "Processed URL 452: https://www.nhatot.com/mua-ban-nha-dat-quan-6-tp-ho-chi-minh/118965878.htm#px=SR-special_display_ad-[PO-2][PL-default]\n",
      "Processed URL 453: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119318235.htm\n",
      "Processed URL 454: https://www.nhatot.com/mua-ban-nha-dat-quan-10-tp-ho-chi-minh/119318225.htm\n",
      "Processed URL 455: https://www.nhatot.com/mua-ban-nha-dat-quan-phu-nhuan-tp-ho-chi-minh/119318223.htm\n",
      "Processed URL 456: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/118789646.htm\n",
      "Processed URL 457: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/115932499.htm\n",
      "Processed URL 458: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119147367.htm\n",
      "Processed URL 459: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119224607.htm\n",
      "Processed URL 460: https://www.nhatot.com/mua-ban-nha-dat-quan-1-tp-ho-chi-minh/117390229.htm\n",
      "Processed URL 461: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-binh-tp-ho-chi-minh/119173490.htm\n",
      "Processed URL 462: https://www.nhatot.com/mua-ban-nha-dat-quan-hai-ba-trung-ha-noi/112559810.htm\n",
      "Processed URL 463: https://www.nhatot.com/mua-ban-nha-dat-quan-thanh-xuan-ha-noi/119291697.htm#px=SR-special_display_ad-[PO-13][PL-default]\n",
      "Processed URL 464: https://www.nhatot.com/mua-ban-nha-dat-quan-4-tp-ho-chi-minh/119318204.htm\n",
      "Processed URL 465: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119292340.htm\n",
      "Processed URL 466: https://www.nhatot.com/mua-ban-nha-dat-quan-cau-giay-ha-noi/119318196.htm\n",
      "Processed URL 467: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-di-an-binh-duong/108885899.htm\n",
      "Processed URL 468: https://www.nhatot.com/mua-ban-nha-dat-quan-10-tp-ho-chi-minh/118939405.htm\n",
      "Processed URL 469: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119277729.htm\n",
      "Processed URL 470: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119318182.htm\n",
      "Processed URL 471: https://www.nhatot.com/mua-ban-nha-dat-quan-dong-da-ha-noi/118689707.htm\n",
      "Processed URL 472: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/116283081.htm\n",
      "Processed URL 473: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thuy-can-tho/119211768.htm\n",
      "Processed URL 474: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119145173.htm\n",
      "Processed URL 475: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/119318170.htm\n",
      "Processed URL 476: https://www.nhatot.com/mua-ban-nha-dat-quan-tay-ho-ha-noi/119318166.htm\n",
      "Processed URL 477: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318163.htm\n",
      "Processed URL 478: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/118835142.htm\n",
      "Processed URL 479: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/116585893.htm\n",
      "Processed URL 480: https://www.nhatot.com/mua-ban-nha-dat-quan-3-tp-ho-chi-minh/117850799.htm\n",
      "Processed URL 481: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119318150.htm\n",
      "Processed URL 482: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-thanh-tp-ho-chi-minh/118758938.htm\n",
      "Processed URL 483: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/118779956.htm\n",
      "Processed URL 484: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119318123.htm#px=SR-special_display_ad-[PO-14][PL-default]\n",
      "Processed URL 485: https://www.nhatot.com/mua-ban-nha-dat-quan-go-vap-tp-ho-chi-minh/119318145.htm#px=SR-special_display_ad-[PO-15][PL-default]\n",
      "Processed URL 486: https://www.nhatot.com/mua-ban-nha-dat-quan-8-tp-ho-chi-minh/119172782.htm\n",
      "Processed URL 487: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-bien-hoa-dong-nai/119318138.htm#px=SR-special_display_ad-[PO-17][PL-default]\n",
      "Processed URL 488: https://www.nhatot.com/mua-ban-nha-dat-quan-cau-giay-ha-noi/119318128.htm\n",
      "Processed URL 489: https://www.nhatot.com/mua-ban-nha-dat-huyen-hoc-mon-tp-ho-chi-minh/119318126.htm\n",
      "Processed URL 490: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-bien-hoa-dong-nai/117950906.htm\n",
      "Processed URL 491: https://www.nhatot.com/mua-ban-nha-dat-quan-10-tp-ho-chi-minh/117281954.htm\n",
      "Processed URL 492: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119198503.htm#px=SR-special_display_ad-[PO-2][PL-default]\n",
      "Processed URL 493: https://www.nhatot.com/mua-ban-nha-dat-thanh-pho-thu-duc-tp-ho-chi-minh/119041357.htm\n",
      "Processed URL 494: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/118811639.htm#px=SR-special_display_ad-[PO-4][PL-default]\n",
      "Processed URL 495: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318112.htm\n",
      "Processed URL 496: https://www.nhatot.com/mua-ban-nha-dat-quan-12-tp-ho-chi-minh/119129033.htm#px=SR-special_display_ad-[PO-6][PL-default]\n",
      "Processed URL 497: https://www.nhatot.com/mua-ban-nha-dat-quan-tan-phu-tp-ho-chi-minh/119318107.htm\n",
      "Processed URL 498: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/119318105.htm\n",
      "Processed URL 499: https://www.nhatot.com/mua-ban-nha-dat-quan-7-tp-ho-chi-minh/119267668.htm\n",
      "Processed URL 500: https://www.nhatot.com/mua-ban-nha-dat-huyen-binh-chanh-tp-ho-chi-minh/119318104.htm\n",
      "Processed URL 501: https://www.nhatot.com/mua-ban-nha-dat-quan-binh-tan-tp-ho-chi-minh/117987211.htm\n"
     ]
    }
   ],
   "source": [
    "from tenacity import retry, wait_fixed, stop_after_attempt\n",
    "\n",
    "# Function to extract data from a single page\n",
    "@retry(wait=wait_fixed(2), stop=stop_after_attempt(3))  # Wait 2 seconds between retries, retry 3 times\n",
    "def extract_data(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until price element is available or timeout after 10 seconds\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pyhk1dv')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "        except AttributeError:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            address = soup.find_all(\"span\", class_=\"bwq0cbs\")[4].text\n",
    "        except (IndexError, AttributeError):\n",
    "            address = None\n",
    "\n",
    "        try:\n",
    "            price_m2 = soup.find(\"span\", itemprop=\"price_m2\").text\n",
    "        except AttributeError:\n",
    "            price_m2 = None\n",
    "\n",
    "        try:\n",
    "            rooms = soup.find(\"span\", itemprop=\"rooms\").text\n",
    "        except AttributeError:\n",
    "            rooms = None\n",
    "\n",
    "        try:\n",
    "            toilets = soup.find(\"span\", itemprop=\"toilets\").text\n",
    "        except AttributeError:\n",
    "            toilets = None\n",
    "\n",
    "        try:\n",
    "            direction = soup.find(\"span\", itemprop=\"direction\").text\n",
    "        except AttributeError:\n",
    "            direction = None\n",
    "\n",
    "        try:\n",
    "            floors = soup.find(\"span\", itemprop=\"floors\").text\n",
    "        except AttributeError:\n",
    "            floors = None\n",
    "\n",
    "        try:\n",
    "            property_legal_document = soup.find(\"span\", itemprop=\"property_legal_document\").text\n",
    "        except AttributeError:\n",
    "            property_legal_document = None\n",
    "\n",
    "        try:\n",
    "            house_type = soup.find(\"span\", itemprop=\"house_type\").text\n",
    "        except AttributeError:\n",
    "            house_type = None\n",
    "\n",
    "        try:\n",
    "            furnishing_sell = soup.find(\"span\", itemprop=\"furnishing_sell\").text\n",
    "        except AttributeError:\n",
    "            furnishing_sell = None\n",
    "\n",
    "        try:\n",
    "            width = soup.find(\"span\", itemprop=\"width\").text\n",
    "        except AttributeError:\n",
    "            width = None\n",
    "\n",
    "        try:\n",
    "            length = soup.find(\"span\", itemprop=\"length\").text\n",
    "        except AttributeError:\n",
    "            length = None\n",
    "\n",
    "        try:\n",
    "            living_size = soup.find(\"span\", itemprop=\"living_size\").text\n",
    "        except AttributeError:\n",
    "            living_size = None\n",
    "\n",
    "        try:\n",
    "            size = soup.find(\"span\", itemprop=\"size\").text\n",
    "        except AttributeError:\n",
    "            size = None\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            \"price\": price,\n",
    "            \"address\": address,\n",
    "            \"price_m2\": price_m2,\n",
    "            \"rooms\": rooms,\n",
    "            \"toilets\": toilets,\n",
    "            \"direction\": direction,\n",
    "            \"floors\": floors,\n",
    "            \"property_legal_document\": property_legal_document,\n",
    "            \"house_type\": house_type,\n",
    "            \"furnishing_sell\": furnishing_sell,\n",
    "            \"width\": width,\n",
    "            \"length\": length,\n",
    "            \"living_size\": living_size,\n",
    "            \"size\": size\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_list, filename='muaBanNhaDat2.csv'):\n",
    "    if not data_list:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    keys = data_list[0].keys()  # Use the keys from the first dictionary as headers\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data_list)\n",
    "\n",
    "# Main function to process all URLs and save results\n",
    "def main():\n",
    "    # Replace this with your actual DataFrame or list of URLs\n",
    "    frame = pd.read_csv('nhaDatLinks1.csv')  # Assuming you already have the 'Links' data in CSV\n",
    "    all_data = []\n",
    "    i = 0\n",
    "    for url in frame['Links']:\n",
    "        data = extract_data(url)\n",
    "        i+=1\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "        print(f\"Processed URL {i}: {url}\")\n",
    "\n",
    "    save_to_csv(all_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>address</th>\n",
       "      <th>price_m2</th>\n",
       "      <th>rooms</th>\n",
       "      <th>toilets</th>\n",
       "      <th>direction</th>\n",
       "      <th>floors</th>\n",
       "      <th>property_legal_document</th>\n",
       "      <th>house_type</th>\n",
       "      <th>furnishing_sell</th>\n",
       "      <th>width</th>\n",
       "      <th>length</th>\n",
       "      <th>living_size</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1,79 tỷ</td>\n",
       "      <td>Đường Mạc Đĩnh Chi, Phường An Cư, Quận Ninh Ki...</td>\n",
       "      <td>61,72 triệu/m²</td>\n",
       "      <td>2 phòng</td>\n",
       "      <td>2 phòng</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Đã có sổ</td>\n",
       "      <td>Nhà ngõ, hẻm</td>\n",
       "      <td>Hoàn thiện cơ bản</td>\n",
       "      <td>5 m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13,50 tỷ</td>\n",
       "      <td>Đường Trần Bạch Đằng, Phường An Khánh, Quận Ni...</td>\n",
       "      <td>112,50 triệu/m²</td>\n",
       "      <td>4 phòng</td>\n",
       "      <td>4 phòng</td>\n",
       "      <td>Tây Nam</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Đã có sổ</td>\n",
       "      <td>Nhà mặt phố, mặt tiền</td>\n",
       "      <td>Hoàn thiện cơ bản</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9,20 tỷ</td>\n",
       "      <td>Đường Nguyễn Thượng Hiền, Phường 5, Quận Bình ...</td>\n",
       "      <td>177,78 triệu/m²</td>\n",
       "      <td>4 phòng</td>\n",
       "      <td>5 phòng</td>\n",
       "      <td>Tây Nam</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Đã có sổ</td>\n",
       "      <td>Nhà ngõ, hẻm</td>\n",
       "      <td>Nội thất cao cấp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3,60 tỷ</td>\n",
       "      <td>Đường SINCO, Phường Bình Trị Đông B, Quận Bình...</td>\n",
       "      <td>56,25 triệu/m²</td>\n",
       "      <td>1 phòng</td>\n",
       "      <td>1 phòng</td>\n",
       "      <td>Tây Nam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Đã có sổ</td>\n",
       "      <td>Nhà ngõ, hẻm</td>\n",
       "      <td>Bàn giao thô</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11 tỷ</td>\n",
       "      <td>95/, Đường Nguyễn Thái Học, Phường Cầu Ông Lãn...</td>\n",
       "      <td>166,67 triệu/m²</td>\n",
       "      <td>4 phòng</td>\n",
       "      <td>2 phòng</td>\n",
       "      <td>Đông Bắc</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Đã có sổ</td>\n",
       "      <td>Nhà ngõ, hẻm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4 m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price                                            address  \\\n",
       "0   1,79 tỷ  Đường Mạc Đĩnh Chi, Phường An Cư, Quận Ninh Ki...   \n",
       "1  13,50 tỷ  Đường Trần Bạch Đằng, Phường An Khánh, Quận Ni...   \n",
       "2   9,20 tỷ  Đường Nguyễn Thượng Hiền, Phường 5, Quận Bình ...   \n",
       "3   3,60 tỷ  Đường SINCO, Phường Bình Trị Đông B, Quận Bình...   \n",
       "4     11 tỷ  95/, Đường Nguyễn Thái Học, Phường Cầu Ông Lãn...   \n",
       "\n",
       "          price_m2    rooms  toilets direction  floors  \\\n",
       "0   61,72 triệu/m²  2 phòng  2 phòng       NaN     1.0   \n",
       "1  112,50 triệu/m²  4 phòng  4 phòng   Tây Nam     3.0   \n",
       "2  177,78 triệu/m²  4 phòng  5 phòng   Tây Nam     4.0   \n",
       "3   56,25 triệu/m²  1 phòng  1 phòng   Tây Nam     NaN   \n",
       "4  166,67 triệu/m²  4 phòng  2 phòng  Đông Bắc     2.0   \n",
       "\n",
       "  property_legal_document             house_type    furnishing_sell width  \\\n",
       "0                Đã có sổ           Nhà ngõ, hẻm  Hoàn thiện cơ bản   5 m   \n",
       "1                Đã có sổ  Nhà mặt phố, mặt tiền  Hoàn thiện cơ bản   NaN   \n",
       "2                Đã có sổ           Nhà ngõ, hẻm   Nội thất cao cấp   NaN   \n",
       "3                Đã có sổ           Nhà ngõ, hẻm       Bàn giao thô   NaN   \n",
       "4                Đã có sổ           Nhà ngõ, hẻm                NaN   4 m   \n",
       "\n",
       "  length living_size size  \n",
       "0    NaN         NaN  NaN  \n",
       "1    NaN         NaN  NaN  \n",
       "2    NaN         NaN  NaN  \n",
       "3    NaN         NaN  NaN  \n",
       "4    NaN         NaN  NaN  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame1 = pd.read_csv('raw_data.csv')\n",
    "frame1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy chi tiết data mua bán căn hộ chung cư"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from a single page\n",
    "def extract_data(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until price element is available or timeout after 10 seconds\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pyhk1dv')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "        except AttributeError:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            address = soup.find_all(\"span\", class_=\"bwq0cbs\")[5].text\n",
    "        except (IndexError, AttributeError):\n",
    "            address = None\n",
    "\n",
    "        try:\n",
    "            price_m2 = soup.find(\"span\", itemprop=\"price_m2\").text\n",
    "        except AttributeError:\n",
    "            price_m2 = None\n",
    "\n",
    "        try:\n",
    "            rooms = soup.find(\"span\", itemprop=\"rooms\").text\n",
    "        except AttributeError:\n",
    "            rooms = None\n",
    "\n",
    "        try:\n",
    "            toilets = soup.find(\"span\", itemprop=\"toilets\").text\n",
    "        except AttributeError:\n",
    "            toilets = None\n",
    "\n",
    "        try:\n",
    "            direction = soup.find(\"span\", itemprop=\"direction\").text\n",
    "        except AttributeError:\n",
    "            direction = None\n",
    "\n",
    "        try:\n",
    "            property_status = soup.find(\"span\", itemprop=\"property_status\").text\n",
    "        except AttributeError:\n",
    "            property_status = None\n",
    "            \n",
    "        try:\n",
    "            balconydirection = soup.find(\"span\", itemprop=\"balconydirection\").text\n",
    "        except AttributeError:\n",
    "            balconydirection = None\n",
    "            \n",
    "        try:\n",
    "            property_legal_document = soup.find(\"span\", itemprop=\"property_legal_document\").text\n",
    "        except AttributeError:\n",
    "            property_legal_document = None\n",
    "\n",
    "        try:\n",
    "            apartment_type = soup.find(\"span\", itemprop=\"apartment_type\").text\n",
    "        except AttributeError:\n",
    "            apartment_type = None\n",
    "\n",
    "        try:\n",
    "            furnishing_sell = soup.find(\"span\", itemprop=\"furnishing_sell\").text\n",
    "        except AttributeError:\n",
    "            furnishing_sell = None\n",
    "\n",
    "        try:\n",
    "            size = soup.find(\"span\", itemprop=\"size\").text\n",
    "        except AttributeError:\n",
    "            size = None\n",
    "            \n",
    "        try:\n",
    "            apartment_feature = soup.find(\"span\", itemprop=\"apartment_feature\").text\n",
    "        except AttributeError:\n",
    "            apartment_feature = None\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            \"price\": price,\n",
    "            \"address\": address,\n",
    "            \"price_m2\": price_m2,\n",
    "            \"rooms\": rooms,\n",
    "            \"toilets\": toilets,\n",
    "            \"direction\": direction,\n",
    "            \"property_status\": property_status,\n",
    "            \"balconydirection\": balconydirection,\n",
    "            \"property_legal_document\": property_legal_document,\n",
    "            \"apartment_type\": apartment_type,\n",
    "            \"furnishing_sell\": furnishing_sell,\n",
    "            \"size\": size,\n",
    "            \"apartment_feature\": apartment_feature\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_list, filename='raw_data.csv'):\n",
    "    if not data_list:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    keys = data_list[0].keys()  # Use the keys from the first dictionary as headers\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data_list)\n",
    "\n",
    "# Main function to process all URLs and save results\n",
    "def main():\n",
    "    # Replace this with your actual DataFrame or list of URLs\n",
    "    frame = pd.read_csv('muaBanCanHoChungCuLinks.csv')  # Assuming you already have the 'Links' data in CSV\n",
    "    all_data = []\n",
    "    \n",
    "    for url in frame['Links']:\n",
    "        data = extract_data(url)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "        print(f\"Processed URL: {url}\")\n",
    "\n",
    "    save_to_csv(all_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy chi tiết data mua bán mặt bằng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from a single page\n",
    "def extract_data(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until price element is available or timeout after 10 seconds\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pyhk1dv')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "        except AttributeError:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            address = soup.find_all(\"span\", class_=\"bwq0cbs\")[3].text\n",
    "        except (IndexError, AttributeError):\n",
    "            address = None\n",
    "\n",
    "        try:\n",
    "            price_m2 = soup.find(\"span\", itemprop=\"price_m2\").text\n",
    "        except AttributeError:\n",
    "            price_m2 = None\n",
    "\n",
    "        try:\n",
    "            direction = soup.find(\"span\", itemprop=\"direction\").text\n",
    "        except AttributeError:\n",
    "            direction = None\n",
    "            \n",
    "        try:\n",
    "            property_legal_document = soup.find(\"span\", itemprop=\"property_legal_document\").text\n",
    "        except AttributeError:\n",
    "            property_legal_document = None\n",
    "\n",
    "        try:\n",
    "            commercial_type = soup.find(\"span\", itemprop=\"commercial_type\").text\n",
    "        except AttributeError:\n",
    "            commercial_type = None\n",
    "\n",
    "        try:\n",
    "            furnishing_sell = soup.find(\"span\", itemprop=\"furnishing_sell\").text\n",
    "        except AttributeError:\n",
    "            furnishing_sell = None\n",
    "\n",
    "        try:\n",
    "            size = soup.find(\"span\", itemprop=\"size\").text\n",
    "        except AttributeError:\n",
    "            size = None\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            \"price\": price,\n",
    "            \"address\": address,\n",
    "            \"price_m2\": price_m2,\n",
    "            \"direction\": direction,\n",
    "            \"property_legal_document\": property_legal_document,\n",
    "            \"commercial_type\": commercial_type,\n",
    "            \"furnishing_sell\": furnishing_sell,\n",
    "            \"size\": size,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_list, filename='raw_data.csv'):\n",
    "    if not data_list:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    keys = data_list[0].keys()  # Use the keys from the first dictionary as headers\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data_list)\n",
    "\n",
    "# Main function to process all URLs and save results\n",
    "def main():\n",
    "    # Replace this with your actual DataFrame or list of URLs\n",
    "    frame = pd.read_csv('muaBanMatBangLinks.csv')  # Assuming you already have the 'Links' data in CSV\n",
    "    all_data = []\n",
    "    \n",
    "    for url in frame['Links']:\n",
    "        data = extract_data(url)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "        print(f\"Processed URL: {url}\")\n",
    "\n",
    "    save_to_csv(all_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy chi tiết data mua bán đất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from a single page\n",
    "def extract_data(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until price element is available or timeout after 10 seconds\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pyhk1dv')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "        except AttributeError:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            address = soup.find_all(\"span\", class_=\"bwq0cbs\")[3].text\n",
    "        except (IndexError, AttributeError):\n",
    "            address = None\n",
    "\n",
    "        try:\n",
    "            price_m2 = soup.find(\"span\", itemprop=\"price_m2\").text\n",
    "        except AttributeError:\n",
    "            price_m2 = None\n",
    "\n",
    "        try:\n",
    "            direction = soup.find(\"span\", itemprop=\"direction\").text\n",
    "        except AttributeError:\n",
    "            direction = None\n",
    "            \n",
    "        try:\n",
    "            property_legal_document = soup.find(\"span\", itemprop=\"property_legal_document\").text\n",
    "        except AttributeError:\n",
    "            property_legal_document = None\n",
    "\n",
    "        try:\n",
    "            land_type = soup.find(\"span\", itemprop=\"land_type\").text\n",
    "        except AttributeError:\n",
    "            land_type = None\n",
    "\n",
    "        try:\n",
    "            pty_characteristics = soup.find(\"span\", itemprop=\"pty_characteristics\").text\n",
    "        except AttributeError:\n",
    "            pty_characteristics = None\n",
    "\n",
    "        try:\n",
    "            size = soup.find(\"span\", itemprop=\"size\").text\n",
    "        except AttributeError:\n",
    "            size = None\n",
    "        \n",
    "        try:\n",
    "            width = soup.find(\"span\", itemprop=\"width\").text\n",
    "        except AttributeError:\n",
    "            width = None\n",
    "\n",
    "        try:\n",
    "            length = soup.find(\"span\", itemprop=\"length\").text\n",
    "        except AttributeError:\n",
    "            length = None\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            \"price\": price,\n",
    "            \"address\": address,\n",
    "            \"price_m2\": price_m2,\n",
    "            \"direction\": direction,\n",
    "            \"property_legal_document\": property_legal_document,\n",
    "            \"land_type\": land_type,\n",
    "            \"pty_characteristics\": pty_characteristics,\n",
    "            \"size\": size,\n",
    "            \"width\": width,\n",
    "            \"length\": length,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_list, filename='raw_data.csv'):\n",
    "    if not data_list:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    keys = data_list[0].keys()  # Use the keys from the first dictionary as headers\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data_list)\n",
    "\n",
    "# Main function to process all URLs and save results\n",
    "def main():\n",
    "    # Replace this with your actual DataFrame or list of URLs\n",
    "    frame = pd.read_csv('muaBanDatLinks.csv')  # Assuming you already have the 'Links' data in CSV\n",
    "    all_data = []\n",
    "    \n",
    "    for url in frame['Links']:\n",
    "        data = extract_data(url)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "        print(f\"Processed URL: {url}\")\n",
    "\n",
    "    save_to_csv(all_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy chi tiết data cho thuê căn hộ chung cư"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from a single page\n",
    "def extract_data(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until price element is available or timeout after 10 seconds\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pyhk1dv')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "        except AttributeError:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            address = soup.find_all(\"span\", class_=\"bwq0cbs\")[0].text\n",
    "        except (IndexError, AttributeError):\n",
    "            address = None\n",
    "\n",
    "        try:\n",
    "            ad_type = soup.find(\"span\", itemprop=\"ad_type\").text\n",
    "        except AttributeError:\n",
    "            ad_type = None\n",
    "            \n",
    "        try:\n",
    "            rooms = soup.find(\"span\", itemprop=\"rooms\").text\n",
    "        except AttributeError:\n",
    "            rooms = None\n",
    "            \n",
    "        try:\n",
    "            toilets = soup.find(\"span\", itemprop=\"toilets\").text\n",
    "        except AttributeError:\n",
    "            toilets = None\n",
    "\n",
    "        try:\n",
    "            direction = soup.find(\"span\", itemprop=\"direction\").text\n",
    "        except AttributeError:\n",
    "            direction = None\n",
    "            \n",
    "        try:\n",
    "            balconydirection = soup.find(\"span\", itemprop=\"balconydirection\").text\n",
    "        except AttributeError:\n",
    "            balconydirection = None\n",
    "            \n",
    "        try:\n",
    "            property_legal_document = soup.find(\"span\", itemprop=\"property_legal_document\").text\n",
    "        except AttributeError:\n",
    "            property_legal_document = None\n",
    "\n",
    "        try:\n",
    "            apartment_type = soup.find(\"span\", itemprop=\"apartment_type\").text\n",
    "        except AttributeError:\n",
    "            apartment_type = None\n",
    "\n",
    "        try:\n",
    "            furnishing_sell = soup.find(\"span\", itemprop=\"furnishing_sell\").text\n",
    "        except AttributeError:\n",
    "            furnishing_sell = None\n",
    "\n",
    "        try:\n",
    "            size = soup.find(\"span\", itemprop=\"size\").text\n",
    "        except AttributeError:\n",
    "            size = None\n",
    "        \n",
    "        try:\n",
    "            deposit = soup.find(\"span\", itemprop=\"deposit\").text\n",
    "        except AttributeError:\n",
    "            deposit = None\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            \"price\": price,\n",
    "            \"address\": address,\n",
    "            \"ad_type\": ad_type,\n",
    "            \"rooms\": rooms,\n",
    "            \"toilets\": toilets,\n",
    "            \"direction\": direction,\n",
    "            \"balconydirection\": balconydirection,\n",
    "            \"property_legal_document\": property_legal_document,\n",
    "            \"apartment_type\": apartment_type,\n",
    "            \"furnishing_sell\": furnishing_sell,\n",
    "            \"deposit\": deposit,\n",
    "            \"size\": size,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_list, filename='choThueCanHoChungCu.csv'):\n",
    "    if not data_list:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    keys = data_list[0].keys()  # Use the keys from the first dictionary as headers\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data_list)\n",
    "\n",
    "# Main function to process all URLs and save results\n",
    "def main():\n",
    "    # Replace this with your actual DataFrame or list of URLs\n",
    "    frame = pd.read_csv('choThueCanHoChungCuLinks.csv')  # Assuming you already have the 'Links' data in CSV\n",
    "    all_data = []\n",
    "    \n",
    "    for url in frame['Links']:\n",
    "        data = extract_data(url)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "        print(f\"Processed URL: {url}\")\n",
    "\n",
    "    save_to_csv(all_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy chi tiết data cho thuê nhà ở"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from a single page\n",
    "def extract_data(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until price element is available or timeout after 10 seconds\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pyhk1dv')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "        except AttributeError:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            address = soup.find_all(\"span\", class_=\"bwq0cbs\")[0].text\n",
    "        except (IndexError, AttributeError):\n",
    "            address = None\n",
    "\n",
    "        try:\n",
    "            ad_type = soup.find(\"span\", itemprop=\"ad_type\").text\n",
    "        except AttributeError:\n",
    "            ad_type = None\n",
    "\n",
    "        try:\n",
    "            rooms = soup.find(\"span\", itemprop=\"rooms\").text\n",
    "        except AttributeError:\n",
    "            rooms = None\n",
    "            \n",
    "        try:\n",
    "            toilets = soup.find(\"span\", itemprop=\"toilets\").text\n",
    "        except AttributeError:\n",
    "            toilets = None\n",
    "\n",
    "        try:\n",
    "            direction = soup.find(\"span\", itemprop=\"direction\").text\n",
    "        except AttributeError:\n",
    "            direction = None\n",
    "            \n",
    "        try:\n",
    "            floors = soup.find(\"span\", itemprop=\"floors\").text\n",
    "        except AttributeError:\n",
    "            floors = None\n",
    "            \n",
    "        try:\n",
    "            property_legal_document = soup.find(\"span\", itemprop=\"property_legal_document\").text\n",
    "        except AttributeError:\n",
    "            property_legal_document = None\n",
    "\n",
    "        try:\n",
    "            house_type = soup.find(\"span\", itemprop=\"house_type\").text\n",
    "        except AttributeError:\n",
    "            house_type = None\n",
    "\n",
    "        try:\n",
    "            furnishing_sell = soup.find(\"span\", itemprop=\"furnishing_sell\").text\n",
    "        except AttributeError:\n",
    "            furnishing_sell = None\n",
    "\n",
    "        try:\n",
    "            size = soup.find(\"span\", itemprop=\"size\").text\n",
    "        except AttributeError:\n",
    "            size = None\n",
    "        \n",
    "        try:\n",
    "            deposit = soup.find(\"span\", itemprop=\"deposit\").text\n",
    "        except AttributeError:\n",
    "            deposit = None\n",
    "            \n",
    "        try:\n",
    "            living_size = soup.find(\"span\", itemprop=\"living_size\").text\n",
    "        except AttributeError:\n",
    "            living_size = None\n",
    "            \n",
    "        try:\n",
    "            pty_characteristics = soup.find(\"span\", itemprop=\"pty_characteristics\").text\n",
    "        except AttributeError:\n",
    "            pty_characteristics = None\n",
    "            \n",
    "        try:\n",
    "            width = soup.find(\"span\", itemprop=\"width\").text\n",
    "        except AttributeError:\n",
    "            width = None\n",
    "            \n",
    "        try:\n",
    "            length = soup.find(\"span\", itemprop=\"length\").text\n",
    "        except AttributeError:\n",
    "            length = None\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            \"price\": price,\n",
    "            \"address\": address,\n",
    "            \"ad_type\": ad_type,\n",
    "            \"rooms\": rooms,\n",
    "            \"toilets\": toilets,\n",
    "            \"direction\": direction,\n",
    "            \"floors\": floors,\n",
    "            \"property_legal_document\": property_legal_document,\n",
    "            \"house_type\": house_type,\n",
    "            \"furnishing_sell\": furnishing_sell,\n",
    "            \"deposit\": deposit,\n",
    "            \"size\": size,\n",
    "            \"living_size\": living_size,\n",
    "            \"pty_characteristics\": pty_characteristics,\n",
    "            \"width\": width,\n",
    "            \"length\": length,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_list, filename='choThueNhaO.csv'):\n",
    "    if not data_list:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    keys = data_list[0].keys()  # Use the keys from the first dictionary as headers\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data_list)\n",
    "\n",
    "# Main function to process all URLs and save results\n",
    "def main():\n",
    "    # Replace this with your actual DataFrame or list of URLs\n",
    "    frame = pd.read_csv('choThueNhaOLinks.csv')  # Assuming you already have the 'Links' data in CSV\n",
    "    all_data = []\n",
    "    \n",
    "    for url in frame['Links']:\n",
    "        data = extract_data(url)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "        print(f\"Processed URL: {url}\")\n",
    "\n",
    "    save_to_csv(all_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy chi tiết data cho thuê mặt bằng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from a single page\n",
    "def extract_data(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until price element is available or timeout after 10 seconds\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pyhk1dv')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "        except AttributeError:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            address = soup.find_all(\"span\", class_=\"bwq0cbs\")[0].text\n",
    "        except (IndexError, AttributeError):\n",
    "            address = None\n",
    "\n",
    "        try:\n",
    "            ad_type = soup.find(\"span\", itemprop=\"ad_type\").text\n",
    "        except AttributeError:\n",
    "            ad_type = None\n",
    "\n",
    "        try:\n",
    "            direction = soup.find(\"span\", itemprop=\"direction\").text\n",
    "        except AttributeError:\n",
    "            direction = None\n",
    "            \n",
    "        try:\n",
    "            property_legal_document = soup.find(\"span\", itemprop=\"property_legal_document\").text\n",
    "        except AttributeError:\n",
    "            property_legal_document = None\n",
    "\n",
    "        try:\n",
    "            commercial_type = soup.find(\"span\", itemprop=\"commercial_type\").text\n",
    "        except AttributeError:\n",
    "            commercial_type = None\n",
    "\n",
    "        try:\n",
    "            furnishing_sell = soup.find(\"span\", itemprop=\"furnishing_sell\").text\n",
    "        except AttributeError:\n",
    "            furnishing_sell = None\n",
    "\n",
    "        try:\n",
    "            size = soup.find(\"span\", itemprop=\"size\").text\n",
    "        except AttributeError:\n",
    "            size = None\n",
    "        \n",
    "        try:\n",
    "            deposit = soup.find(\"span\", itemprop=\"deposit\").text\n",
    "        except AttributeError:\n",
    "            deposit = None\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            \"price\": price,\n",
    "            \"address\": address,\n",
    "            \"ad_type\": ad_type,\n",
    "            \"direction\": direction,\n",
    "            \"property_legal_document\": property_legal_document,\n",
    "            \"commercial_type\": commercial_type,\n",
    "            \"furnishing_sell\": furnishing_sell,\n",
    "            \"deposit\": deposit,\n",
    "            \"size\": size,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_list, filename='choThueMatBang.csv'):\n",
    "    if not data_list:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    keys = data_list[0].keys()  # Use the keys from the first dictionary as headers\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data_list)\n",
    "\n",
    "# Main function to process all URLs and save results\n",
    "def main():\n",
    "    # Replace this with your actual DataFrame or list of URLs\n",
    "    frame = pd.read_csv('choThueMatBangLinks.csv')  # Assuming you already have the 'Links' data in CSV\n",
    "    all_data = []\n",
    "    \n",
    "    for url in frame['Links']:\n",
    "        data = extract_data(url)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "        print(f\"Processed URL: {url}\")\n",
    "\n",
    "    save_to_csv(all_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy chi tiết data cho thuê đất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from a single page\n",
    "def extract_data(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until price element is available or timeout after 10 seconds\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pyhk1dv')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "        except AttributeError:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            address = soup.find_all(\"span\", class_=\"bwq0cbs\")[0].text\n",
    "        except (IndexError, AttributeError):\n",
    "            address = None\n",
    "\n",
    "        try:\n",
    "            ad_type = soup.find(\"span\", itemprop=\"ad_type\").text\n",
    "        except AttributeError:\n",
    "            ad_type = None\n",
    "\n",
    "        try:\n",
    "            direction = soup.find(\"span\", itemprop=\"direction\").text\n",
    "        except AttributeError:\n",
    "            direction = None\n",
    "            \n",
    "        try:\n",
    "            property_legal_document = soup.find(\"span\", itemprop=\"property_legal_document\").text\n",
    "        except AttributeError:\n",
    "            property_legal_document = None\n",
    "\n",
    "        try:\n",
    "            land_type = soup.find(\"span\", itemprop=\"land_type\").text\n",
    "        except AttributeError:\n",
    "            land_type = None\n",
    "\n",
    "        try:\n",
    "            width = soup.find(\"span\", itemprop=\"width\").text\n",
    "        except AttributeError:\n",
    "            width = None\n",
    "            \n",
    "        try:\n",
    "            length = soup.find(\"span\", itemprop=\"length\").text\n",
    "        except AttributeError:\n",
    "            length = None\n",
    "\n",
    "        try:\n",
    "            size = soup.find(\"span\", itemprop=\"size\").text\n",
    "        except AttributeError:\n",
    "            size = None\n",
    "        \n",
    "        try:\n",
    "            deposit = soup.find(\"span\", itemprop=\"deposit\").text\n",
    "        except AttributeError:\n",
    "            deposit = None\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            \"price\": price,\n",
    "            \"address\": address,\n",
    "            \"ad_type\": ad_type,\n",
    "            \"direction\": direction,\n",
    "            \"property_legal_document\": property_legal_document,\n",
    "            \"land_type\": land_type,\n",
    "            \"width\": width,\n",
    "            \"length\": length,\n",
    "            \"deposit\": deposit,\n",
    "            \"size\": size,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_list, filename='choThueDat.csv'):\n",
    "    if not data_list:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    keys = data_list[0].keys()  # Use the keys from the first dictionary as headers\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data_list)\n",
    "\n",
    "# Main function to process all URLs and save results\n",
    "def main():\n",
    "    # Replace this with your actual DataFrame or list of URLs\n",
    "    frame = pd.read_csv('choThueDatLinks.csv')  # Assuming you already have the 'Links' data in CSV\n",
    "    all_data = []\n",
    "    \n",
    "    for url in frame['Links']:\n",
    "        data = extract_data(url)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "        print(f\"Processed URL: {url}\")\n",
    "\n",
    "    save_to_csv(all_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lấy chi tiết data cho thuê phòng trọ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from a single page\n",
    "def extract_data(url):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait until price element is available or timeout after 10 seconds\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'pyhk1dv')))\n",
    "\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            price = soup.find(\"b\", class_='pyhk1dv').text\n",
    "        except AttributeError:\n",
    "            price = None\n",
    "\n",
    "        try:\n",
    "            address = soup.find_all(\"span\", class_=\"bwq0cbs\")[0].text\n",
    "        except (IndexError, AttributeError):\n",
    "            address = None\n",
    "\n",
    "        try:\n",
    "            ad_type = soup.find(\"span\", itemprop=\"ad_type\").text\n",
    "        except AttributeError:\n",
    "            ad_type = None\n",
    "\n",
    "        try:\n",
    "            furnishing_rent = soup.find(\"span\", itemprop=\"furnishing_rent\").text\n",
    "        except AttributeError:\n",
    "            furnishing_rent = None\n",
    "            \n",
    "        try:\n",
    "            size = soup.find(\"span\", itemprop=\"size\").text\n",
    "        except AttributeError:\n",
    "            size = None\n",
    "        \n",
    "        try:\n",
    "            deposit = soup.find(\"span\", itemprop=\"deposit\").text\n",
    "        except AttributeError:\n",
    "            deposit = None\n",
    "        \n",
    "        driver.quit()\n",
    "\n",
    "        return {\n",
    "            \"price\": price,\n",
    "            \"address\": address,\n",
    "            \"ad_type\": ad_type,\n",
    "            \"furnishing_rent\": furnishing_rent, \n",
    "            \"deposit\": deposit,\n",
    "            \"size\": size,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL {url}: {e}\")\n",
    "        driver.quit()\n",
    "        return None\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(data_list, filename='choThuePhongTro.csv'):\n",
    "    if not data_list:\n",
    "        print(\"No data to save.\")\n",
    "        return\n",
    "    keys = data_list[0].keys()  # Use the keys from the first dictionary as headers\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(data_list)\n",
    "\n",
    "# Main function to process all URLs and save results\n",
    "def main():\n",
    "    # Replace this with your actual DataFrame or list of URLs\n",
    "    frame = pd.read_csv('choThuePhongTroLinks.csv')  # Assuming you already have the 'Links' data in CSV\n",
    "    all_data = []\n",
    "    \n",
    "    for url in frame['Links']:\n",
    "        data = extract_data(url)\n",
    "        if data:\n",
    "            all_data.append(data)\n",
    "        print(f\"Processed URL: {url}\")\n",
    "\n",
    "    save_to_csv(all_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
